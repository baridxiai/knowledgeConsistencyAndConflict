~/miniconda3/bin/python measure_consistency_mlama.py  --batch_size 1 --probed_layers 0 4 8 12 16 20 24 28 31 --model_name meta-llama/Llama-3.1-8B-Instruct --matrix_lang en --embedded_lang ta --output_prefix evaluations/llama-3.1-8b --intervened_ffn_layers  5 10 15 18 20  --beam_topk 5 --ranking_topk 5
~/miniconda3/bin/python measure_consistency_mlama.py  --batch_size 1 --probed_layers 0 4 8 12 16 20 24 28 31 --model_name meta-llama/Llama-3.1-8B-Instruct --matrix_lang en --embedded_lang de --output_prefix evaluations/llama-3.1-8b --intervened_ffn_layers  5 10 15 18 20  --beam_topk 5 --ranking_topk 5
~/miniconda3/bin/python measure_consistency_mlama.py  --batch_size 1 --probed_layers 0 4 8 12 16 20 24 28 31 --model_name meta-llama/Llama-3.1-8B-Instruct --matrix_lang en --embedded_lang id --output_prefix evaluations/llama-3.1-8b --intervened_ffn_layers  5 10 15 18 20  --beam_topk 5 --ranking_topk 5
~/miniconda3/bin/python measure_consistency_mlama.py  --batch_size 1 --probed_layers 0 4 8 12 16 20 24 28 31 --model_name meta-llama/Llama-3.1-8B-Instruct --matrix_lang en --embedded_lang ar --output_prefix evaluations/llama-3.1-8b --intervened_ffn_layers  5 10 15 18 20  --beam_topk 5 --ranking_topk 5
~/miniconda3/bin/python measure_consistency_mlama.py  --batch_size 1 --probed_layers 0 4 8 12 16 20 24 28 31 --model_name meta-llama/Llama-3.1-8B-Instruct --matrix_lang en --embedded_lang baseline-decoder --output_prefix evaluations/llama-3.1-8b --intervened_ffn_layers  5 10 15 18 20  --beam_topk 5 --ranking_topk 5
#~/miniconda3/bin/python measure_consistency_mlama.py  --batch_size 1 --probed_layers 0 2 4 6 8 10 12 14 15 --model_name meta-llama/Llama-3.2-1B-Instruct --matrix_lang en --embedded_lang ta --output_prefix evaluations/llama-3.1-8b --intervened_ffn_layers  5 10 15 18 20  --beam_topk 5 --ranking_topk 5
#~/miniconda3/bin/python measure_consistency_mlama.py  --batch_size 1 --probed_layers 0 2 4 6 8 10 12 14 15 --model_name meta-llama/Llama-3.2-1B-Instruct --matrix_lang en --embedded_lang de --output_prefix evaluations/llama-3.1-8b --intervened_ffn_layers  5 10 15 18 20  --beam_topk 5 --ranking_topk 5
#~/miniconda3/bin/python measure_consistency_mlama.py  --batch_size 1 --probed_layers 0 2 4 6 8 10 12 14 15 --model_name meta-llama/Llama-3.2-1B-Instruct --matrix_lang en --embedded_lang id --output_prefix evaluations/llama-3.1-8b --intervened_ffn_layers  5 10 15 18 20  --beam_topk 5 --ranking_topk 5
#~/miniconda3/bin/python measure_consistency_mlama.py  --batch_size 1 --probed_layers 0 2 4 6 8 10 12 14 15 --model_name meta-llama/Llama-3.2-1B-Instruct --matrix_lang en --embedded_lang ar --output_prefix evaluations/llama-3.1-8b --intervened_ffn_layers  5 10 15 18 20  --beam_topk 5 --ranking_topk 5
