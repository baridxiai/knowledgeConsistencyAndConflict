{
    "output_dir":"./model_checkpoint_finetuner",
    "per_device_train_batch_size":53,
    "per_gpu_eval_batch_size":30,
    "overwrite_output_dir":true,
    "num_train_epochs":50,
    "save_steps":5000,
    "save_total_limit":5,
    "report_to":"wandb",
    "remove_unused_columns":false,
    "max_grad_norm":5.0,
    "gradient_accumulation_steps":1,
    "evaluation_strategy":"epoch",
    "learning_rate":1e-6,
    "adam_beta1":0.9,
    "adam_beta2":0.999,
    "adam_epsilon":1e-6,
    "warmup_steps": 0,
    "lr_scheduler_type":"inverse_sqrt",
    "fp16":true,
    "fp16_backend":true,
    "fp16_full_eval":true,
    "fp16_opt_level":true
}