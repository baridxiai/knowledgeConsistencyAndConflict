{
    "output_dir":"./model_checkpoint_finetuner_base_isolated",
    "per_device_train_batch_size":64,
    "per_gpu_eval_batch_size":30,
    "overwrite_output_dir":true,
    "num_train_epochs":10,
    "save_steps":500,
    "save_total_limit":1,
    "report_to":"wandb",
    "remove_unused_columns":false,
    "max_grad_norm":5.0,
    "gradient_accumulation_steps":1,
    "evaluation_strategy":"epoch",
    "learning_rate":1e-7,
    "adam_beta1":0.9,
    "adam_beta2":0.999,
    "adam_epsilon":1e-7,
    "warmup_steps": 0,
    "lr_scheduler_type":"constant",
    "fp16":true,
    "fp16_backend":true,
    "fp16_full_eval":true,
    "fp16_opt_level":true
}
